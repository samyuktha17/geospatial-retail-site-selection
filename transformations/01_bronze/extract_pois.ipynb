{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Databricks notebook source",
        "# MAGIC %md",
        "# MAGIC # POI Extraction from OSM - Bronze Layer",
        "# MAGIC",
        "# MAGIC Extracts raw Point of Interest (POI) data from OpenStreetMap PBF files.",
        "# MAGIC",
        "# MAGIC **Purpose**: Raw extraction of POI nodes with their tags.",
        "# MAGIC",
        "# MAGIC **Input**: OSM PBF file from Bronze volume",
        "# MAGIC **Output**: Bronze table with raw POI data (osm_id, osm_type, latitude, longitude, tags)",
        "# MAGIC"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md",
        "## Prerequisites",
        "",
        "**Required Library**: `pyosmium`",
        "",
        "This library must be installed on the cluster.",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install pyyaml"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install osmium"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import osmium",
        "import yaml",
        "from pyspark.sql import functions as F",
        "from pyspark.sql.types import *",
        "from datetime import datetime",
        "import os",
        "",
        "# Notebook parameters",
        "dbutils.widgets.text(\"catalog\", \"\")",
        "dbutils.widgets.text(\"bronze_schema\", \"\")",
        "dbutils.widgets.text(\"osm_region\", \"\")",
        "dbutils.widgets.text(\"config_path\", \"\")",
        "",
        "# Extract parameters",
        "catalog = dbutils.widgets.get(\"catalog\")",
        "bronze_schema = dbutils.widgets.get(\"bronze_schema\")",
        "osm_region = dbutils.widgets.get(\"osm_region\")",
        "config_path = dbutils.widgets.get(\"config_path\")",
        "",
        "assert catalog and bronze_schema and osm_region and config_path, \"Missing required parameters\"",
        "",
        "# Load configuration",
        "with open(config_path, 'r') as f:",
        "    config = yaml.safe_load(f)",
        "",
        "poi_config = config['poi_extraction']",
        "table_config = config['table_names']",
        "paths_config = config['paths']",
        "",
        "# Define paths",
        "osm_file_path = f\"/Volumes/{catalog}/{bronze_schema}/osm_data/{osm_region}-latest.osm.pbf\"",
        "output_table = f\"{catalog}.{bronze_schema}.bronze_{table_config['bronze_raw_suffix']}\"",
        "temp_path = paths_config['temp_path']"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check if OSM file exists",
        "try:",
        "    dbutils.fs.ls(osm_file_path)",
        "except Exception as e:",
        "    raise RuntimeError(f\"OSM file not found: {osm_file_path}. Please ensure OSM download task completed successfully.\") from e"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md",
        "## Define POI Handler",
        "",
        "Extracts nodes that have POI tags (amenity, shop, leisure, etc.).",
        "Only nodes with relevant POI tags are extracted - nodes without POI tags are skipped.",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class POIHandler(osmium.SimpleHandler):",
        "    \"\"\"Handler to extract POI nodes from OSM data based on tag categories\"\"\"",
        "    ",
        "    def __init__(self, extract_all=True, poi_tag_categories=None):",
        "        super().__init__()",
        "        self.pois = []",
        "        ",
        "        # Default POI tag categories (used when extract_all=True)",
        "        default_poi_tags = [",
        "            'amenity', 'shop', 'leisure', 'tourism', 'office', ",
        "            'public_transport', 'railway', 'natural', 'building'",
        "        ]",
        "        ",
        "        # If extract_all=True, use all default POI tags",
        "        # If extract_all=False, use only the specified poi_tag_categories",
        "        if extract_all:",
        "            self.poi_tag_categories = default_poi_tags",
        "        else:",
        "            # When extract_all=False, poi_tag_categories must be provided",
        "            self.poi_tag_categories = poi_tag_categories if poi_tag_categories else default_poi_tags",
        "    ",
        "    def _has_poi_tag(self, tags):",
        "        \"\"\"Check if element has any POI tag from the configured categories\"\"\"",
        "        tag_keys = {tag.k for tag in tags}",
        "        return any(poi_tag in tag_keys for poi_tag in self.poi_tag_categories)",
        "    ",
        "    def node(self, n):",
        "        \"\"\"Extract nodes with POI tags\"\"\"",
        "        # Only extract nodes that have POI tags and valid location",
        "        if not n.location.valid():",
        "            return",
        "        ",
        "        if self._has_poi_tag(n.tags):",
        "            # Use dict() constructor as shown in osmium documentation",
        "            tags_dict = dict(n.tags)",
        "            ",
        "            # Only add if tags dict is not empty",
        "            if tags_dict:",
        "                self.pois.append({",
        "                    'osm_id': str(n.id),",
        "                    'osm_type': 'node',",
        "                    'latitude': n.location.lat,",
        "                    'longitude': n.location.lon,",
        "                    'tags': tags_dict",
        "                })"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md",
        "## Extract POIs from OSM File",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Parse OSM file and extract POIs",
        "extract_all = poi_config.get('extract_all', True)",
        "poi_tag_categories = poi_config.get('poi_tag_categories', [])",
        "",
        "# Initialize handler with configuration",
        "handler = POIHandler(extract_all=extract_all, poi_tag_categories=poi_tag_categories)",
        "",
        "# Parse OSM file directly from Unity Catalog volume",
        "# With SINGLE_USER mode, Unity Catalog volumes are FUSE-mounted and accessible as POSIX paths",
        "# osmium can read directly from /Volumes/ paths",
        "",
        "",
        "# Verify file exists",
        "if not os.path.exists(osm_file_path):",
        "    raise RuntimeError(f\"OSM file not found at: {osm_file_path}\")",
        "",
        "# Parse with osmium directly from Unity Catalog volume path",
        "handler.apply_file(osm_file_path)",
        "",
        "poi_count = len(handler.pois)",
        "",
        "if poi_count == 0:",
        "    raise RuntimeError(\"No POIs found in OSM file. Check if file contains POI data with matching tags.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convert POIs to Spark DataFrame directly",
        "# Define schema for Spark DataFrame",
        "# Tags will be stored as MapType(StringType(), StringType())",
        "schema = StructType([",
        "    StructField(\"osm_id\", StringType(), False),",
        "    StructField(\"osm_type\", StringType(), False),",
        "    StructField(\"latitude\", DoubleType(), True),",
        "    StructField(\"longitude\", DoubleType(), True),",
        "    StructField(\"tags\", MapType(StringType(), StringType()), True)",
        "])",
        "",
        "# Create Spark DataFrame directly from list of dictionaries",
        "poi_df = spark.createDataFrame(handler.pois, schema=schema)",
        "",
        "display(poi_df.limit(10))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md",
        "## Write to Bronze Table",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write to Bronze table",
        "poi_df.write \\",
        "    .format(\"delta\") \\",
        "    .mode(\"overwrite\") \\",
        "    .option(\"overwriteSchema\", \"true\") \\",
        "    .option(\"delta.autoOptimize.optimizeWrite\", \"true\") \\",
        "    .saveAsTable(output_table)",
        "",
        "# Summary statistics with tag validation",
        "summary = spark.sql(f\"\"\"",
        "    SELECT ",
        "        COUNT(*) as total_pois,",
        "        COUNT(DISTINCT osm_id) as unique_pois,",
        "        COUNT(DISTINCT osm_type) as osm_types,",
        "        COUNT(CASE WHEN latitude IS NOT NULL AND longitude IS NOT NULL THEN 1 END) as pois_with_coords,",
        "        COUNT(CASE WHEN tags IS NOT NULL THEN 1 END) as pois_with_tags,",
        "        COUNT(CASE WHEN tags IS NULL THEN 1 END) as pois_without_tags",
        "    FROM {output_table}",
        "\"\"\")",
        "",
        "display(summary)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}