{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Databricks notebook source\n",
        "# MAGIC %md\n",
        "# MAGIC # Trade Area Feature Aggregation\n",
        "# MAGIC\n",
        "# MAGIC Aggregates H3 features to trade area level:\n",
        "# MAGIC 1. H3 index trade areas \u2192 get h3_cell_ids\n",
        "# MAGIC 2. Join to h3_features_gold on h3_cell_id\n",
        "# MAGIC 3. Aggregate by store_number"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import functions as F\n",
        "import yaml\n",
        "\n",
        "dbutils.widgets.text(\"catalog\", \"geo_site_selection\")\n",
        "dbutils.widgets.text(\"silver_schema\", \"silver\")\n",
        "dbutils.widgets.text(\"gold_schema\", \"gold\")\n",
        "dbutils.widgets.text(\"config_path\", \"/Workspace/resources/configs/h3_features_config.yml\")\n",
        "dbutils.widgets.text(\"trade_area_table\", \"\", \"Trade Area Table (optional)\")\n",
        "dbutils.widgets.text(\"output_table_override\", \"\", \"Output Table (optional)\")\n",
        "\n",
        "catalog = dbutils.widgets.get(\"catalog\")\n",
        "silver_schema = dbutils.widgets.get(\"silver_schema\")\n",
        "gold_schema = dbutils.widgets.get(\"gold_schema\")\n",
        "config_path = dbutils.widgets.get(\"config_path\")\n",
        "trade_area_table_override = dbutils.widgets.get(\"trade_area_table\")\n",
        "output_table_override = dbutils.widgets.get(\"output_table_override\")\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "H3_RESOLUTION = config['h3_grid']['resolution']\n",
        "\n",
        "if trade_area_table_override and trade_area_table_override.strip():\n",
        "    trade_area_table = trade_area_table_override.strip()\n",
        "    default_output = trade_area_table.split('.')[-1] + \"_features\"\n",
        "else:\n",
        "    trade_area_table = f\"{catalog}.{silver_schema}.silver_rmc_urbanicity_based_isochrones\"\n",
        "    default_output = \"rmc_trade_area_features\"\n",
        "\n",
        "if output_table_override and output_table_override.strip():\n",
        "    output_table_name = output_table_override.strip()\n",
        "else:\n",
        "    output_table_name = default_output\n",
        "\n",
        "print(f\"Input: {trade_area_table}\")\n",
        "print(f\"Output: {catalog}.{gold_schema}.gold_{output_table_name}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md\n",
        "## H3 Index Trade Areas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "trade_areas = spark.table(trade_area_table)\n",
        "\n",
        "ta_h3 = trade_areas.select(\n",
        "    F.col(\"store_number\"),\n",
        "    F.col(\"latitude\"),\n",
        "    F.col(\"longitude\"),\n",
        "    F.col(\"store_type\"),\n",
        "    F.col(\"city\"),\n",
        "    F.col(\"state\"),\n",
        "    F.col(\"drive_time_minutes\"),\n",
        "    F.col(\"area_sqkm\"),\n",
        "    F.col(\"geometry\"),  # Keep geometry for output\n",
        "    F.explode(F.expr(f\"h3_polyfillash3string(ST_AsText(geometry), {H3_RESOLUTION})\")).alias(\"h3_cell_id\")\n",
        ")\n",
        "\n",
        "print(f\"Trade areas indexed with H3\")\n",
        "display(ta_h3)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(trade_areas)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md\n",
        "## Join to H3 Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "h3_features = spark.table(f\"{catalog}.{gold_schema}.silver_h3_features\").drop(\"h3_geometry\", \"h3_resolution\", \"processing_timestamp\")\n",
        "\n",
        "ta_with_features = ta_h3.join(h3_features, \"h3_cell_id\", \"inner\")\n",
        "\n",
        "print(f\"Joined trade areas with H3 features\")\n",
        "display(ta_with_features.limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md\n",
        "## Aggregate by Store"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "demo_vars = config['demographic_variables']\n",
        "count_vars = (\n",
        "    demo_vars['population'] + \n",
        "    demo_vars['income'] + \n",
        "    demo_vars['households'] + \n",
        "    demo_vars['education'] + \n",
        "    demo_vars['employment'] + \n",
        "    demo_vars['housing'] + \n",
        "    demo_vars['commute']\n",
        ")\n",
        "median_vars = demo_vars['median']\n",
        "\n",
        "existing_count_vars = [v for v in count_vars if v in ta_with_features.columns]\n",
        "existing_median_vars = [v for v in median_vars if v in ta_with_features.columns]\n",
        "poi_cols = [c for c in ta_with_features.columns if c.startswith('poi_count_')]\n",
        "competitor_cols = [c for c in ta_with_features.columns if c.startswith('competitor_count_')]\n",
        "distance_cols = [c for c in ta_with_features.columns if c.startswith('distance_to_')]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg_exprs = []\n",
        "\n",
        "# Count variables: sum (convert negatives to positive for demo purposes)\n",
        "for var in existing_count_vars:\n",
        "    agg_exprs.append(F.abs(F.sum(var)).cast(\"long\").alias(var))\n",
        "\n",
        "# POI counts: sum (convert negatives to positive)\n",
        "for col in poi_cols:\n",
        "    agg_exprs.append(F.abs(F.sum(col)).cast(\"long\").alias(col))\n",
        "agg_exprs.append(F.abs(F.sum(\"total_poi_count\")).cast(\"long\").alias(\"total_poi_count\"))\n",
        "\n",
        "# Competitor counts: sum (convert negatives to positive)\n",
        "for col in competitor_cols:\n",
        "    agg_exprs.append(F.abs(F.sum(col)).cast(\"long\").alias(col))\n",
        "agg_exprs.append(F.abs(F.sum(\"total_competitor_count\")).cast(\"long\").alias(\"total_competitor_count\"))\n",
        "\n",
        "# Median/rate variables: avg (convert negatives to positive)\n",
        "for var in existing_median_vars:\n",
        "    agg_exprs.append(F.abs(F.avg(var)).alias(var))\n",
        "if 'per_capita_income' in ta_with_features.columns:\n",
        "    agg_exprs.append(F.abs(F.avg(\"per_capita_income\")).alias(\"per_capita_income\"))\n",
        "\n",
        "# Distance features: min (keep as-is, distances should be positive)\n",
        "for col in distance_cols:\n",
        "    agg_exprs.append(F.min(col).alias(col))\n",
        "\n",
        "# Population density and urbanicity: avg (convert negatives to positive)\n",
        "agg_exprs.extend([\n",
        "    F.abs(F.avg(\"urbanicity_score\")).alias(\"urbanicity_score\"),\n",
        "    F.count(\"h3_cell_id\").alias(\"h3_cell_count\"),\n",
        "    F.first(\"geometry\").alias(\"geometry\")  # Keep the isochrone geometry\n",
        "])\n",
        "\n",
        "ta_features_agg = ta_with_features.groupBy(\n",
        "    \"store_number\",\n",
        "    \"latitude\",\n",
        "    \"longitude\",\n",
        "    \"store_type\",\n",
        "    \"city\",\n",
        "    \"state\",\n",
        "    # \"urbanicity_category\",\n",
        "    \"drive_time_minutes\",\n",
        "    \"area_sqkm\"\n",
        ").agg(*agg_exprs)\n",
        "\n",
        "display(ta_features_agg.limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(ta_features_agg)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md\n",
        "## Write to Gold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ta_features_final = ta_features_agg.withColumn(\"processing_timestamp\", F.current_timestamp())\n",
        "\n",
        "numeric_cols = [\n",
        "    field.name for field in ta_features_final.schema.fields \n",
        "    if field.dataType.typeName() in ['long', 'double', 'integer', 'float']\n",
        "    and field.name not in ['latitude', 'longitude', 'drive_time_minutes', 'area_sqkm']\n",
        "]\n",
        "ta_features_final = ta_features_final.fillna(0, subset=numeric_cols)\n",
        "\n",
        "# Ensure one record per store (deduplication)\n",
        "# Keep first occurrence if there are any duplicates\n",
        "from pyspark.sql.window import Window\n",
        "window_spec = Window.partitionBy(\"store_number\").orderBy(F.desc(\"processing_timestamp\"))\n",
        "ta_features_final = ta_features_final.withColumn(\"row_num\", F.row_number().over(window_spec)).filter(F.col(\"row_num\") == 1).drop(\"row_num\")\n",
        "\n",
        "output_table = f\"{catalog}.{gold_schema}.gold_{output_table_name}\"\n",
        "\n",
        "print(f\"Records to write: {ta_features_final.count()}\")\n",
        "\n",
        "(\n",
        "    ta_features_final\n",
        "    .write\n",
        "    .format(\"delta\")\n",
        "    .mode(\"overwrite\")\n",
        "    .option(\"overwriteSchema\", \"true\")\n",
        "    .saveAsTable(output_table)\n",
        ")\n",
        "\n",
        "print(f\"Written to {output_table}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(spark.sql(f\"\"\"\n",
        "  SELECT\n",
        "    COUNT(*) as total_trade_areas,\n",
        "    ROUND(AVG(area_sqkm), 2) as avg_area_sqkm,\n",
        "    ROUND(AVG(total_population), 0) as avg_population,\n",
        "    ROUND(AVG(total_poi_count), 0) as avg_poi_count,\n",
        "    ROUND(AVG(total_competitor_count), 0) as avg_competitor_count,\n",
        "    ROUND(AVG(h3_cell_count), 0) as avg_h3_cells\n",
        "  FROM {output_table}\n",
        "\"\"\"))"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}