{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Databricks notebook source\n",
        "# MAGIC %md\n",
        "# MAGIC # H3 Feature Engineering for Site Selection Modeling\n",
        "# MAGIC\n",
        "# MAGIC Generates H3-8 resolution features by aggregating:\n",
        "# MAGIC - POI data from OSM\n",
        "# MAGIC - Demographics from Census block groups (area-weighted)\n",
        "# MAGIC - Competition data\n",
        "# MAGIC - Distance features to RMC locations and competitors\n",
        "# MAGIC - Urbanicity scores\n",
        "# MAGIC\n",
        "# MAGIC Output: `h3_features_gold` table in gold schema"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install folium"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from datetime import datetime\n",
        "import yaml\n",
        "import folium\n",
        "import json\n",
        "\n",
        "# Notebook parameters\n",
        "dbutils.widgets.text(\"catalog\", \"\")\n",
        "dbutils.widgets.text(\"bronze_schema\", \"\")\n",
        "dbutils.widgets.text(\"silver_schema\", \"\")\n",
        "dbutils.widgets.text(\"gold_schema\", \"\")\n",
        "dbutils.widgets.text(\"state_fips\", \"\")\n",
        "dbutils.widgets.text(\"config_path\", \"\")\n",
        "\n",
        "catalog = dbutils.widgets.get(\"catalog\")\n",
        "bronze_schema = dbutils.widgets.get(\"bronze_schema\")\n",
        "silver_schema = dbutils.widgets.get(\"silver_schema\")\n",
        "gold_schema = dbutils.widgets.get(\"gold_schema\")\n",
        "state_fips = dbutils.widgets.get(\"state_fips\")\n",
        "config_path = dbutils.widgets.get(\"config_path\")\n",
        "\n",
        "assert catalog and bronze_schema and silver_schema and gold_schema and state_fips and config_path, \\\n",
        "    \"Missing required parameters\"\n",
        "\n",
        "# Load configuration\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "H3_RESOLUTION = config['h3_grid']['resolution']\n",
        "LAT_STEP = config['h3_grid']['grid_sampling']['lat_step']\n",
        "LON_STEP = config['h3_grid']['grid_sampling']['lon_step']\n",
        "URBANICITY_WEIGHTS = config['urbanicity']['weights']\n",
        "NULL_DISTANCE_VALUE = config['distance']['null_value']"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load state boundary\n",
        "state_df = spark.table(f\"{catalog}.{bronze_schema}.bronze_census_states\") \\\n",
        "    .filter(F.col(\"state_fips\") == state_fips)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate H3 cells covering state\n",
        "h3_cells_df = state_df.select(\n",
        "    F.explode(F.expr(f\"h3_polyfillash3string(ST_AsText(geometry), {H3_RESOLUTION})\")).alias(\"h3_cell_id\")\n",
        ").cache()\n",
        "\n",
        "display(h3_cells_df.limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get H3 cell boundaries and clip to state\n",
        "h3_base_df = h3_cells_df.select(\n",
        "    F.col(\"h3_cell_id\"),\n",
        "    F.expr(\"ST_GeomFromGeoJSON(h3_boundaryasgeojson(h3_cell_id))\").alias(\"h3_geometry\"),\n",
        "    F.lit(H3_RESOLUTION).alias(\"h3_resolution\")\n",
        ")\n",
        "\n",
        "state_boundary_broadcast = F.broadcast(state_df.select(F.col(\"geometry\").alias(\"state_geometry\")))\n",
        "\n",
        "h3_base_df = h3_base_df.crossJoin(state_boundary_broadcast) \\\n",
        "    .filter(F.expr(\"ST_Intersects(h3_geometry, state_geometry)\")) \\\n",
        "    .withColumn(\"h3_geometry\", F.expr(\"ST_Intersection(h3_geometry, state_geometry)\")) \\\n",
        "    .withColumn(\"h3_area_sqkm\", F.expr(\"ST_Area(h3_geometry) / 1000000\")) \\\n",
        "    .select(\"h3_cell_id\", \"h3_geometry\", \"h3_resolution\", \"h3_area_sqkm\") \\\n",
        "    .cache()\n",
        "\n",
        "display(h3_base_df.limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "h3_sample = h3_base_df.limit(20000)\n",
        "\n",
        "h3_geojson = h3_sample.withColumn(\n",
        "    \"geojson\",\n",
        "    F.expr(\"ST_AsGeoJSON(h3_geometry)\")\n",
        ").select(\"h3_cell_id\", \"geojson\").collect()\n",
        "\n",
        "features = [\n",
        "    {\n",
        "        \"type\": \"Feature\",\n",
        "        \"properties\": {\"h3_cell_id\": row[\"h3_cell_id\"]},\n",
        "        \"geometry\": json.loads(row[\"geojson\"])\n",
        "    }\n",
        "    for row in h3_geojson\n",
        "]\n",
        "\n",
        "m = folium.Map(location=[ 42.40, -71.38], zoom_start=6)\n",
        "folium.GeoJson(\n",
        "    {\"type\": \"FeatureCollection\", \"features\": features},\n",
        "    style_function=lambda x: {\"fillColor\": \"blue\", \"color\": \"black\", \"weight\": 1, \"fillOpacity\": 0.3}\n",
        ").add_to(m)\n",
        "\n",
        "m"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md\n",
        "## Step 2: Aggregate POIs to H3 Cells\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load POI data\n",
        "pois_df = spark.table(f\"{catalog}.{silver_schema}.silver_osm_pois\") \\\n",
        "    .select(\n",
        "        F.col(\"latitude\"),\n",
        "        F.col(\"longitude\"),\n",
        "        F.col(\"poi_category\"),\n",
        "        F.expr(\"ST_Point(longitude, latitude, 4326)\").alias(\"poi_point\")\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(pois_df.groupBy(\"poi_category\").agg(F.count(\"*\")))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(pois_df.agg(F.count(\"*\")))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pois_sample_df = pois_df.limit(1000)\n",
        "poi_geojson = pois_sample_df.withColumn(\n",
        "    \"geojson\",\n",
        "    F.expr(\"ST_AsGeoJSON(poi_point)\")\n",
        ").select(\"poi_category\", \"geojson\").collect()\n",
        "\n",
        "features = [\n",
        "    {\n",
        "        \"type\": \"Feature\",\n",
        "        \"properties\": {\"poi_category\": row[\"poi_category\"]},\n",
        "        \"geometry\": json.loads(row[\"geojson\"])\n",
        "    }\n",
        "    for row in poi_geojson\n",
        "]\n",
        "\n",
        "m = folium.Map(location=[ 42.40, -71.38], zoom_start=6)\n",
        "folium.GeoJson(\n",
        "    {\"type\": \"FeatureCollection\", \"features\": features},\n",
        "    style_function=lambda x: {\"fillColor\": \"blue\", \"color\": \"black\", \"weight\": 1, \"fillOpacity\": 0.3}\n",
        ").add_to(m)\n",
        "\n",
        "m"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Spatial join POIs to H3 cells and aggregate by category\n",
        "poi_h3_join = h3_base_df.alias(\"h3\").join(\n",
        "    pois_df.alias(\"poi\"),\n",
        "    F.expr(\"ST_Contains(h3.h3_geometry, poi.poi_point)\"),\n",
        "    \"left\"\n",
        ")\n",
        "display(poi_h3_join.limit(10))\n",
        "\n",
        "poi_category_agg = poi_h3_join.groupBy(\"h3_cell_id\") \\\n",
        "    .pivot(\"poi_category\") \\\n",
        "    .agg(F.count(\"poi_point\"))\n",
        "\n",
        "poi_features = poi_category_agg\n",
        "poi_category_cols = [col for col in poi_features.columns if col != \"h3_cell_id\"]\n",
        "\n",
        "poi_features = poi_features.withColumn(\n",
        "    \"total_poi_count\",\n",
        "    sum([F.coalesce(F.col(c), F.lit(0)) for c in poi_category_cols])\n",
        ")\n",
        "\n",
        "for col in poi_category_cols:\n",
        "    poi_features = poi_features.withColumnRenamed(col, f\"poi_count_{col}\")\n",
        "\n",
        "poi_count_cols = [col for col in poi_features.columns if col.startswith(\"poi_count_\") or col == \"total_poi_count\"]\n",
        "poi_features = poi_features.fillna(0, subset=poi_count_cols)\n",
        "\n",
        "display(poi_features.limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(poi_features.agg(F.sum(F.col(\"total_poi_count\"))).collect()[0][0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md\n",
        "## Step 3: Aggregate Demographics from Block Groups (Area-Weighted)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load block group geometries and demographics\n",
        "bg_geom_df = spark.table(f\"{catalog}.{bronze_schema}.bronze_census_blockgroups\") \\\n",
        "    .select(\n",
        "        F.col(\"geoid\").alias(\"bg_geoid\"),\n",
        "        F.col(\"geometry\").alias(\"bg_geometry\")\n",
        "    )\n",
        "\n",
        "bg_demo_df = spark.table(f\"{catalog}.{bronze_schema}.bronze_census_demographics\") \\\n",
        "    .withColumn(\"geoid\", F.concat(F.col(\"state\"), F.col(\"county\"), F.col(\"tract\"), F.col(\"block_group\")))\n",
        "\n",
        "bg_df = bg_geom_df.join(bg_demo_df, bg_geom_df.bg_geoid == bg_demo_df.geoid, \"inner\") \\\n",
        "    .drop(bg_demo_df.geoid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Spatial join H3 cells with block groups and calculate intersection ratios\n",
        "bg_h3_intersect = h3_base_df.alias(\"h3\").join(\n",
        "    bg_df.alias(\"bg\"),\n",
        "    F.expr(\"ST_Intersects(h3.h3_geometry, bg.bg_geometry)\"),\n",
        "    \"inner\"\n",
        ")\n",
        "\n",
        "bg_h3_intersect = bg_h3_intersect.withColumn(\n",
        "    \"intersection_area\",\n",
        "    F.expr(\"ST_Area(ST_Intersection(bg_geometry, h3_geometry))\")\n",
        ").withColumn(\n",
        "    \"bg_total_area\",\n",
        "    F.expr(\"ST_Area(bg_geometry)\")\n",
        ").withColumn(\n",
        "    \"intersection_ratio\",\n",
        "    F.col(\"intersection_area\") / F.col(\"bg_total_area\")\n",
        ").cache()\n",
        "\n",
        "display(bg_h3_intersect.select(\"h3_cell_id\", \"bg_geoid\", \"intersection_ratio\").limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load demographic variables from config\n",
        "demo_vars = config['demographic_variables']\n",
        "\n",
        "pop_vars = demo_vars['population']\n",
        "income_vars = demo_vars['income']\n",
        "median_vars = demo_vars['median']\n",
        "household_vars = demo_vars['households']\n",
        "education_vars = demo_vars['education']\n",
        "employment_vars = demo_vars['employment']\n",
        "housing_vars = demo_vars['housing']\n",
        "commute_vars = demo_vars['commute']\n",
        "\n",
        "count_vars = pop_vars + income_vars + household_vars + education_vars + employment_vars + housing_vars + commute_vars"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Area-weighted aggregation for count variables\n",
        "existing_count_vars = [v for v in count_vars if v in bg_h3_intersect.columns]\n",
        "\n",
        "weighted_cols = [F.col(\"h3_cell_id\"), F.col(\"bg_geoid\"), F.col(\"intersection_ratio\")]\n",
        "weighted_cols.extend([\n",
        "    (F.coalesce(F.col(var), F.lit(0)) * F.col(\"intersection_ratio\")).alias(f\"{var}_weighted\")\n",
        "    for var in existing_count_vars\n",
        "])\n",
        "\n",
        "bg_h3_weighted = bg_h3_intersect.select(weighted_cols)\n",
        "\n",
        "agg_exprs = [\n",
        "    F.sum(f\"{var}_weighted\").cast(\"long\").alias(var) \n",
        "    for var in existing_count_vars\n",
        "]\n",
        "\n",
        "demo_count_features = bg_h3_weighted.groupBy(\"h3_cell_id\").agg(*agg_exprs)\n",
        "display(demo_count_features.limit(2))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Take median and rate variables from largest overlapping block group\n",
        "existing_median_vars = [v for v in median_vars if v in bg_h3_intersect.columns]\n",
        "\n",
        "rate_vars = existing_median_vars.copy()\n",
        "if 'per_capita_income' in bg_h3_intersect.columns:\n",
        "    rate_vars.append('per_capita_income')\n",
        "\n",
        "window_spec = Window.partitionBy(\"h3_cell_id\").orderBy(F.desc(\"intersection_ratio\"))\n",
        "\n",
        "demo_rate_features = bg_h3_intersect.withColumn(\"rank\", F.row_number().over(window_spec)) \\\n",
        "    .filter(F.col(\"rank\") == 1) \\\n",
        "    .select(F.col(\"h3_cell_id\"), *[F.col(v) for v in rate_vars])    \n",
        "\n",
        "demo_features = demo_count_features.join(demo_rate_features, \"h3_cell_id\", \"outer\")\n",
        "\n",
        "count_cols = [c for c in demo_count_features.columns if c != \"h3_cell_id\"]\n",
        "demo_features = demo_features.fillna(0, subset=count_cols)\n",
        "\n",
        "display(demo_features.limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load competitor locations\n",
        "competitors_df = spark.table(f\"{catalog}.{bronze_schema}.competitor_locations\") \\\n",
        "    .select(\n",
        "        F.col(\"latitude\"),\n",
        "        F.col(\"longitude\"),\n",
        "        F.col(\"store_type\"),\n",
        "        F.expr(\"ST_Point(longitude, latitude, 4326)\").alias(\"competitor_point\")\n",
        "    ).cache()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Spatial join and aggregate competitors by type\n",
        "comp_h3_join = h3_base_df.alias(\"h3\").join(\n",
        "    competitors_df.alias(\"comp\"),\n",
        "    F.expr(\"ST_Contains(h3.h3_geometry, comp.competitor_point)\"),\n",
        "    \"left\"\n",
        ")\n",
        "\n",
        "comp_total_agg = comp_h3_join.groupBy(\"h3_cell_id\") \\\n",
        "    .agg(F.count(\"competitor_point\").alias(\"total_competitor_count\"))\n",
        "\n",
        "comp_brand_agg = comp_h3_join.groupBy(\"h3_cell_id\") \\\n",
        "    .pivot(\"store_type\") \\\n",
        "    .agg(F.count(\"competitor_point\"))\n",
        "\n",
        "comp_brand_cols = [col for col in comp_brand_agg.columns if col != \"h3_cell_id\"]\n",
        "for col in comp_brand_cols:\n",
        "    new_col_name = f\"competitor_count_{col}\".replace(\" \", \"_\")\n",
        "    comp_brand_agg = comp_brand_agg.withColumnRenamed(col, new_col_name)\n",
        "\n",
        "comp_features = comp_total_agg.join(comp_brand_agg, \"h3_cell_id\", \"left\")\n",
        "\n",
        "comp_count_cols = [col for col in comp_features.columns if col.startswith(\"competitor_count_\") or col == \"total_competitor_count\"]\n",
        "comp_features = comp_features.fillna(0, subset=comp_count_cols)\n",
        "\n",
        "display(comp_features.limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md\n",
        "## Step 5: Calculate Distance Features\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate H3 cell centers\n",
        "h3_centers_df = (\n",
        "    h3_base_df\n",
        "    .select(\n",
        "        F.col(\"h3_cell_id\"),\n",
        "        F.expr(\"h3_centeraswkt(h3_cell_id)\").alias(\"center_wkt\")\n",
        "    )\n",
        "    .withColumn(\n",
        "        \"h3_center_point\",\n",
        "        F.expr(\"ST_GeomFromWKT(center_wkt, 4326)\")\n",
        "    )\n",
        "    .withColumn(\n",
        "        \"center_lat\",\n",
        "        F.expr(\"ST_Y(h3_center_point)\")\n",
        "    )\n",
        "    .withColumn(\n",
        "        \"center_lon\",\n",
        "        F.expr(\"ST_X(h3_center_point)\")\n",
        "    )\n",
        "    .select(\"h3_cell_id\", \"h3_center_point\", \"center_lat\", \"center_lon\")\n",
        ")\n",
        "\n",
        "if config['performance']['cache_intermediate_results']:\n",
        "    h3_centers_df = h3_centers_df.cache()\n",
        "\n",
        "display(h3_centers_df.limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load RMC locations and calculate distances in miles\n",
        "rmc_df = spark.table(f\"{catalog}.{bronze_schema}.rmc_retail_locations_grocery\") \\\n",
        "    .select(\n",
        "        F.col(\"latitude\"),\n",
        "        F.col(\"longitude\"),\n",
        "        F.expr(\"ST_Point(longitude, latitude, 4326)\").alias(\"rmc_point\")\n",
        "    )\n",
        "\n",
        "h3_rmc_distances = h3_centers_df.crossJoin(F.broadcast(rmc_df.select(\"rmc_point\"))) \\\n",
        "    .withColumn(\n",
        "        \"distance_miles\",\n",
        "        F.expr(\"ST_Distance(h3_center_point, rmc_point) / 1609.34\")\n",
        "    )\n",
        "\n",
        "rmc_distance_features = h3_rmc_distances.groupBy(\"h3_cell_id\") \\\n",
        "    .agg(F.min(\"distance_miles\").alias(\"distance_to_nearest_rmc_miles\"))\n",
        "\n",
        "display(rmc_distance_features.limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate distances to competitors in miles\n",
        "h3_comp_distances = h3_centers_df.crossJoin(\n",
        "    F.broadcast(competitors_df.select(\"store_type\", \"competitor_point\"))\n",
        ").withColumn(\n",
        "    \"distance_miles\",\n",
        "    F.expr(\"ST_Distance(h3_center_point, competitor_point) / 1609.34\")\n",
        ")\n",
        "\n",
        "# Get minimum distance per H3 cell per brand in single aggregation\n",
        "comp_distance_agg = h3_comp_distances.groupBy(\"h3_cell_id\", \"store_type\") \\\n",
        "    .agg(F.min(\"distance_miles\").alias(\"min_distance_miles\"))\n",
        "\n",
        "# Pivot to get one column per brand\n",
        "comp_distance_pivot = comp_distance_agg.groupBy(\"h3_cell_id\") \\\n",
        "    .pivot(\"store_type\") \\\n",
        "    .agg(F.first(\"min_distance_miles\"))\n",
        "\n",
        "# Rename columns to standard format\n",
        "comp_distance_cols = [col for col in comp_distance_pivot.columns if col != \"h3_cell_id\"]\n",
        "for col in comp_distance_cols:\n",
        "    new_col_name = f\"distance_to_{col.lower().replace(' ', '_')}_miles\"\n",
        "    comp_distance_pivot = comp_distance_pivot.withColumnRenamed(col, new_col_name)\n",
        "\n",
        "# Join RMC and competitor distances\n",
        "distance_features = rmc_distance_features.join(comp_distance_pivot, \"h3_cell_id\", \"left\")\n",
        "\n",
        "# Fill null distances with configured null value\n",
        "distance_cols = [col for col in distance_features.columns if col.startswith(\"distance_to_\")]\n",
        "distance_features = distance_features.fillna(NULL_DISTANCE_VALUE, subset=distance_cols)\n",
        "\n",
        "display(distance_features.limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md\n",
        "## Step 6: Calculate Urbanicity Score\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate population density\n",
        "urbanicity_base = h3_base_df.select(\"h3_cell_id\", \"h3_area_sqkm\") \\\n",
        "    .join(demo_features.select(\"h3_cell_id\", \"total_population\"), \"h3_cell_id\", \"left\") \\\n",
        "    .join(poi_features.select(\"h3_cell_id\", \"total_poi_count\"), \"h3_cell_id\", \"left\") \\\n",
        "    .fillna(0, subset=[\"total_population\", \"total_poi_count\"])\n",
        "\n",
        "display(urbanicity_base.limit(5))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Normalize and calculate urbanicity score with deciles and categories\n",
        "stats = urbanicity_base.agg(\n",
        "    F.min(\"total_poi_count\").alias(\"min_poi_count\"),\n",
        "    F.max(\"total_poi_count\").alias(\"max_poi_count\")\n",
        ").collect()[0]\n",
        "\n",
        "urbanicity_base = urbanicity_base.withColumn(\n",
        "    \"total_poi_count_norm\",\n",
        "    F.when(\n",
        "        (F.lit(stats[\"max_poi_count\"]) - F.lit(stats[\"min_poi_count\"])) > 0,\n",
        "        (F.col(\"total_poi_count\") - F.lit(stats[\"min_poi_count\"])) / (F.lit(stats[\"max_poi_count\"]) - F.lit(stats[\"min_poi_count\"]))\n",
        "    ).otherwise(0)\n",
        ").withColumn(\n",
        "    \"urbanicity_score\",\n",
        "    F.lit(URBANICITY_WEIGHTS['poi_count']) * F.col(\"total_poi_count_norm\")\n",
        ").withColumn(\n",
        "    \"urbanicity_decile\",\n",
        "    F.ntile(10).over(Window.orderBy(\"urbanicity_score\"))\n",
        ").withColumn(\n",
        "    \"urbanicity_category\",\n",
        "    F.when(F.col(\"urbanicity_decile\") >= 8, F.lit(\"urban\"))\n",
        "    .when(F.col(\"urbanicity_decile\") >= 4, F.lit(\"suburban\"))\n",
        "    .otherwise(F.lit(\"rural\"))\n",
        ")\n",
        "\n",
        "urbanicity_features = urbanicity_base.select(\n",
        "    \"h3_cell_id\",\n",
        "    \"total_poi_count_norm\",\n",
        "    \"urbanicity_score\",\n",
        "    \"urbanicity_decile\",\n",
        "    \"urbanicity_category\"\n",
        ").cache()\n",
        "\n",
        "display(urbanicity_features.orderBy(F.desc(\"urbanicity_score\")).limit(10))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "%md\n",
        "## Step 7: Join All Features and Write to Silver Table\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Join all features efficiently\n",
        "h3_features_silver = h3_base_df.select(\"h3_cell_id\", \"h3_geometry\", \"h3_resolution\") \\\n",
        "    .join(poi_features, \"h3_cell_id\", \"left\") \\\n",
        "    .join(demo_features, \"h3_cell_id\", \"left\") \\\n",
        "    .join(comp_features, \"h3_cell_id\", \"left\") \\\n",
        "    .join(distance_features, \"h3_cell_id\", \"left\") \\\n",
        "    .join(\n",
        "        urbanicity_features.select(\"h3_cell_id\", \n",
        "                                    \"total_poi_count_norm\", \"urbanicity_score\", \"urbanicity_decile\", \"urbanicity_category\"),\n",
        "        \"h3_cell_id\",\n",
        "        \"left\"\n",
        "    ) \\\n",
        "    .withColumn(\"processing_timestamp\", F.current_timestamp())\n",
        "\n",
        "# Fill nulls with 0 for numeric columns only\n",
        "numeric_cols = [\n",
        "    field.name for field in h3_features_silver.schema.fields \n",
        "    if field.dataType.typeName() in ['long', 'double', 'integer', 'float']\n",
        "    and field.name not in ['h3_resolution']\n",
        "]\n",
        "h3_features_silver = h3_features_silver.fillna(0, subset=numeric_cols)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "display(h3_features_silver.limit(10))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write to gold table\n",
        "output_table = f\"{catalog}.{gold_schema}.gold_h3_features\"\n",
        "\n",
        "h3_features_silver.write \\\n",
        "    .format(\"delta\") \\\n",
        "    .mode(config['output']['write_mode']) \\\n",
        "    .option(\"overwriteSchema\", \"true\") \\\n",
        "    .saveAsTable(output_table)\n",
        "\n",
        "# Unpersist cached DataFrames\n",
        "h3_cells_df.unpersist()\n",
        "h3_base_df.unpersist()\n",
        "bg_h3_intersect.unpersist()\n",
        "competitors_df.unpersist()\n",
        "urbanicity_features.unpersist()\n",
        "\n",
        "if config['performance']['cache_intermediate_results']:\n",
        "    h3_centers_df.unpersist()\n",
        "\n",
        "display(h3_features_silver.limit(10))"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}